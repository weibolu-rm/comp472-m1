====================================================================================================
(a)
Model: GaussianNB
Params:
Default

(b) Confusion Matrix
[[ 4  0  0  0  0]
 [ 1  5  0  0  0]
 [ 0  0  3  0  0]
 [ 0  0  0 14  0]
 [ 2  2  3  0 16]]

(c)
              precision    recall  f1-score   support

       drugA      0.571     1.000     0.727         4
       drugB      0.714     0.833     0.769         6
       drugC      0.500     1.000     0.667         3
       drugX      1.000     1.000     1.000        14
       drugY      1.000     0.696     0.821        23

    accuracy                          0.840        50
   macro avg      0.757     0.906     0.797        50
weighted avg      0.901     0.840     0.848        50


(d) 
Accuracy of model: 84.00%
Macro-average F1 of model: 79.67%
Weighted-average F1 of model: 84.79%
====================================================================================================
====================================================================================================
(a)
Model: Base-DT
Params:
Default

(b) Confusion Matrix
[[ 4  0  0  0  0]
 [ 1  5  0  0  0]
 [ 0  0  3  0  0]
 [ 0  0  0 14  0]
 [ 0  0  0  0 23]]

(c)
              precision    recall  f1-score   support

       drugA      0.800     1.000     0.889         4
       drugB      1.000     0.833     0.909         6
       drugC      1.000     1.000     1.000         3
       drugX      1.000     1.000     1.000        14
       drugY      1.000     1.000     1.000        23

    accuracy                          0.980        50
   macro avg      0.960     0.967     0.960        50
weighted avg      0.984     0.980     0.980        50


(d) 
Accuracy of model: 98.00%
Macro-average F1 of model: 95.96%
Weighted-average F1 of model: 98.02%
====================================================================================================
====================================================================================================
(a)
Model: Top-DT
Params:
{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}

(b) Confusion Matrix
[[ 4  0  0  0  0]
 [ 1  5  0  0  0]
 [ 0  0  3  0  0]
 [ 0  0  0 14  0]
 [ 0  0  0  0 23]]

(c)
              precision    recall  f1-score   support

       drugA      0.800     1.000     0.889         4
       drugB      1.000     0.833     0.909         6
       drugC      1.000     1.000     1.000         3
       drugX      1.000     1.000     1.000        14
       drugY      1.000     1.000     1.000        23

    accuracy                          0.980        50
   macro avg      0.960     0.967     0.960        50
weighted avg      0.984     0.980     0.980        50


(d) 
Accuracy of model: 98.00%
Macro-average F1 of model: 95.96%
Weighted-average F1 of model: 98.02%
====================================================================================================
====================================================================================================
(a)
Model: PER
Params:
Default

(b) Confusion Matrix
[[ 1  3  0  0  0]
 [ 0  6  0  0  0]
 [ 0  2  0  0  1]
 [ 1 12  0  0  1]
 [ 0  6  0  0 17]]

(c)
              precision    recall  f1-score   support

       drugA      0.500     0.250     0.333         4
       drugB      0.207     1.000     0.343         6
       drugC      0.000     0.000     0.000         3
       drugX      0.000     0.000     0.000        14
       drugY      0.895     0.739     0.810        23

    accuracy                          0.480        50
   macro avg      0.320     0.398     0.297        50
weighted avg      0.476     0.480     0.440        50


(d) 
Accuracy of model: 48.00%
Macro-average F1 of model: 29.71%
Weighted-average F1 of model: 44.02%
====================================================================================================
====================================================================================================
(a)
Model: Base-MLP
Params:
1 hidden layer of 100 neurons, sigmoid/logistic as activation function,
stochastic gradient descent, and default values for the rest of the parameters.

(b) Confusion Matrix
[[ 0  0  0  2  2]
 [ 0  0  0  6  0]
 [ 0  0  0  1  2]
 [ 0  0  0 12  2]
 [ 0  0  0  2 21]]

(c)
              precision    recall  f1-score   support

       drugA      0.000     0.000     0.000         4
       drugB      0.000     0.000     0.000         6
       drugC      0.000     0.000     0.000         3
       drugX      0.522     0.857     0.649        14
       drugY      0.778     0.913     0.840        23

    accuracy                          0.660        50
   macro avg      0.260     0.354     0.298        50
weighted avg      0.504     0.660     0.568        50


(d) 
Accuracy of model: 66.00%
Macro-average F1 of model: 29.77%
Weighted-average F1 of model: 56.80%
====================================================================================================
====================================================================================================
(a)
Model: Top-MLP
Params:
{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(b) Confusion Matrix
[[ 4  0  0  0  0]
 [ 3  2  0  1  0]
 [ 0  0  0  3  0]
 [ 0  0  0 14  0]
 [ 0  1  0  1 21]]

(c)
              precision    recall  f1-score   support

       drugA      0.571     1.000     0.727         4
       drugB      0.667     0.333     0.444         6
       drugC      0.000     0.000     0.000         3
       drugX      0.737     1.000     0.848        14
       drugY      1.000     0.913     0.955        23

    accuracy                          0.820        50
   macro avg      0.595     0.649     0.595        50
weighted avg      0.792     0.820     0.788        50


(d) 
Accuracy of model: 82.00%
Macro-average F1 of model: 59.49%
Weighted-average F1 of model: 78.82%
====================================================================================================
####################################################################################################
Running 10x runs of each models:

GaussianNB()
average accuracy: 84.00%
std accuracy: 1.1102230246251565e-16
average macro average F1: 79.67%
std macro average F1: 1.1102230246251565e-16
average weighted average F1: 84.79%
std weighted average F1: 0.0

DecisionTreeClassifier()
average accuracy: 98.00%
std accuracy: 1.1102230246251565e-16
average macro average F1: 95.96%
std macro average F1: 1.1102230246251565e-16
average weighted average F1: 98.02%
std weighted average F1: 0.0

DecisionTreeClassifier(max_depth=5)
average accuracy: 98.00%
std accuracy: 1.1102230246251565e-16
average macro average F1: 95.96%
std macro average F1: 1.1102230246251565e-16
average weighted average F1: 98.02%
std weighted average F1: 0.0

Perceptron()
average accuracy: 48.00%
std accuracy: 1.1102230246251565e-16
average macro average F1: 29.71%
std macro average F1: 0.0
average weighted average F1: 44.02%
std weighted average F1: 5.551115123125783e-17

MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')
average accuracy: 63.60%
std accuracy: 0.014966629547095779
average macro average F1: 28.72%
std macro average F1: 0.007678421013878384
average weighted average F1: 54.89%
std weighted average F1: 0.01323058649930641

MLPClassifier(activation='tanh', hidden_layer_sizes=(30, 50))
average accuracy: 84.20%
std accuracy: 0.05400000000000002
average macro average F1: 65.10%
std macro average F1: 0.12061868671894414
average weighted average F1: 81.68%
std weighted average F1: 0.06982362265511012
