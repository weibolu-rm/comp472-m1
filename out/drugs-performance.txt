====================================================================================================
(a)
Model: GaussianNB
Params:
Default

(b) Confusion Matrix
[[15  0  0  0  0]
 [10  3  0  0  0]
 [ 0  0 12  0  0]
 [ 0  0  0 37  5]
 [ 7  0  1  0 60]]

(c)
              precision    recall  f1-score   support

       drugA      0.469     1.000     0.638        15
       drugB      1.000     0.231     0.375        13
       drugC      0.923     1.000     0.960        12
       drugX      1.000     0.881     0.937        42
       drugY      0.923     0.882     0.902        68

    accuracy                          0.847       150
   macro avg      0.863     0.799     0.762       150
weighted avg      0.906     0.847     0.844       150


(d) 
Accuracy of model: 84.67%
Macro-average F1 of model: 76.25%
Weighted-average F1 of model: 84.44%
====================================================================================================
====================================================================================================
(a)
Model: Base-DT
Params:
Default

(b) Confusion Matrix
[[15  0  0  0  0]
 [ 4  9  0  0  0]
 [ 0  0 12  0  0]
 [ 0  0  0 41  1]
 [ 0  0  0  0 68]]

(c)
              precision    recall  f1-score   support

       drugA      0.789     1.000     0.882        15
       drugB      1.000     0.692     0.818        13
       drugC      1.000     1.000     1.000        12
       drugX      1.000     0.976     0.988        42
       drugY      0.986     1.000     0.993        68

    accuracy                          0.967       150
   macro avg      0.955     0.934     0.936       150
weighted avg      0.972     0.967     0.966       150


(d) 
Accuracy of model: 96.67%
Macro-average F1 of model: 93.62%
Weighted-average F1 of model: 96.58%
====================================================================================================
====================================================================================================
(a)
Model: Top-DT
Params:
{'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 2}

(b) Confusion Matrix
[[15  0  0  0  0]
 [ 4  9  0  0  0]
 [ 0  0 12  0  0]
 [ 0  0  0 41  1]
 [ 0  0  0  0 68]]

(c)
              precision    recall  f1-score   support

       drugA      0.789     1.000     0.882        15
       drugB      1.000     0.692     0.818        13
       drugC      1.000     1.000     1.000        12
       drugX      1.000     0.976     0.988        42
       drugY      0.986     1.000     0.993        68

    accuracy                          0.967       150
   macro avg      0.955     0.934     0.936       150
weighted avg      0.972     0.967     0.966       150


(d) 
Accuracy of model: 96.67%
Macro-average F1 of model: 93.62%
Weighted-average F1 of model: 96.58%
====================================================================================================
====================================================================================================
(a)
Model: PER
Params:
Default

(b) Confusion Matrix
[[ 0  0  0  0 15]
 [ 0  0  0  0 13]
 [ 0  0  0  0 12]
 [ 0  0  0  0 42]
 [ 0  0  0  0 68]]

(c)
              precision    recall  f1-score   support

       drugA      0.000     0.000     0.000        15
       drugB      0.000     0.000     0.000        13
       drugC      0.000     0.000     0.000        12
       drugX      0.000     0.000     0.000        42
       drugY      0.453     1.000     0.624        68

    accuracy                          0.453       150
   macro avg      0.091     0.200     0.125       150
weighted avg      0.206     0.453     0.283       150


(d) 
Accuracy of model: 45.33%
Macro-average F1 of model: 12.48%
Weighted-average F1 of model: 28.28%
====================================================================================================
====================================================================================================
(a)
Model: Base-MLP
Params:
1 hidden layer of 100 neurons, sigmoid/logistic as activation function,
stochastic gradient descent, and default values for the rest of the parameters.

(b) Confusion Matrix
[[ 0  0  0  5 10]
 [ 0  0  0  9  4]
 [ 0  0  0  6  6]
 [ 0  0  0 25 17]
 [ 0  0  0  1 67]]

(c)
              precision    recall  f1-score   support

       drugA      0.000     0.000     0.000        15
       drugB      0.000     0.000     0.000        13
       drugC      0.000     0.000     0.000        12
       drugX      0.543     0.595     0.568        42
       drugY      0.644     0.985     0.779        68

    accuracy                          0.613       150
   macro avg      0.238     0.316     0.269       150
weighted avg      0.444     0.613     0.512       150


(d) 
Accuracy of model: 61.33%
Macro-average F1 of model: 26.95%
Weighted-average F1 of model: 51.23%
====================================================================================================
====================================================================================================
(a)
Model: Top-MLP
Params:
{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(b) Confusion Matrix
[[13  0  0  2  0]
 [ 6  6  0  0  1]
 [ 0  0  5  7  0]
 [ 2  6 11 22  1]
 [ 0  0  2  3 63]]

(c)
              precision    recall  f1-score   support

       drugA      0.619     0.867     0.722        15
       drugB      0.500     0.462     0.480        13
       drugC      0.278     0.417     0.333        12
       drugX      0.647     0.524     0.579        42
       drugY      0.969     0.926     0.947        68

    accuracy                          0.727       150
   macro avg      0.603     0.639     0.612       150
weighted avg      0.748     0.727     0.732       150


(d) 
Accuracy of model: 72.67%
Macro-average F1 of model: 61.24%
Weighted-average F1 of model: 73.21%
====================================================================================================
####################################################################################################
Running 10x runs of each models:

GaussianNB()
average accuracy: 84.67%
std accuracy: 0.0
average macro average F1: 76.25%
std macro average F1: 0.0
average weighted average F1: 84.44%
std weighted average F1: 0.0

DecisionTreeClassifier()
average accuracy: 96.67%
std accuracy: 1.1102230246251565e-16
average macro average F1: 93.62%
std macro average F1: 1.1102230246251565e-16
average weighted average F1: 96.58%
std weighted average F1: 1.1102230246251565e-16

DecisionTreeClassifier(criterion='entropy', max_depth=8)
average accuracy: 96.67%
std accuracy: 1.1102230246251565e-16
average macro average F1: 93.62%
std macro average F1: 1.1102230246251565e-16
average weighted average F1: 96.58%
std weighted average F1: 1.1102230246251565e-16

Perceptron()
average accuracy: 45.33%
std accuracy: 0.0
average macro average F1: 12.48%
std macro average F1: 0.0
average weighted average F1: 28.28%
std weighted average F1: 5.551115123125783e-17

MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')
average accuracy: 60.33%
std accuracy: 0.007453559924999273
average macro average F1: 26.48%
std macro average F1: 0.0043171200756628005
average weighted average F1: 50.51%
std weighted average F1: 0.007100275605036407

MLPClassifier(activation='tanh', hidden_layer_sizes=(30, 50))
average accuracy: 71.13%
std accuracy: 0.019333333333333338
average macro average F1: 59.75%
std macro average F1: 0.029689827878836842
average weighted average F1: 71.02%
std weighted average F1: 0.019357813117512696
